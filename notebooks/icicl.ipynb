{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5aa9d-b297-4975-93e4-c216b407e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7555863-3261-442f-81e6-8cd326d5e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import neuralprocesses.torch as nps\n",
    "import icicl\n",
    "import stheno\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wbml.plot\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7d329-81e8-4389-a7c6-859856153234",
   "metadata": {},
   "source": [
    "# Construct ICNP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42dae5c-f797-4dfb-8dfc-d409369b061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 1\n",
    "y_dim = 1\n",
    "r_dim = 32\n",
    "encoder_num_layers = 3\n",
    "encoder_width = 128\n",
    "decoder_num_layers = 3\n",
    "decoder_width = 128\n",
    "\n",
    "likelihood = icicl.likelihoods.HeteroscedasticNormalLikelihood()\n",
    "\n",
    "deepset_mlp = icicl.nn.MLP(\n",
    "    in_dim=x_dim + y_dim,\n",
    "    out_dim=r_dim,\n",
    "    num_layers=encoder_num_layers,\n",
    "    width=encoder_width,\n",
    ")\n",
    "deepset = icicl.deepset.DeepSet(phi=encoder_mlp)\n",
    "\n",
    "dataset_deepset_mlp = icicl.nn.MLP(\n",
    "    in_dim=x_dim + y_dim,\n",
    "    out_dim=r_dim,\n",
    "    num_layers=encoder_num_layers,\n",
    "    width=encoder_width,\n",
    ")\n",
    "dataset_deepset = icicl.deepset.DatasetDeepSet(\n",
    "    icicl.deepset.DeepSet(dataset_deepset_mlp)\n",
    ")\n",
    "\n",
    "encoder = icicl.deepset.ICDeepSet(deepset, dataset_deepset)\n",
    "\n",
    "# Change this to be more like Wessels.\n",
    "decoder_mlp = icicl.nn.MLP(\n",
    "    in_dim=2 * r_dim + x_dim,\n",
    "    out_dim=likelihood.out_dim_multiplier * y_dim,\n",
    "    num_layers=decoder_num_layers,\n",
    "    width=decoder_width,\n",
    ")\n",
    "decoder = icicl.cnp.CNPDecoder(decoder_mlp)\n",
    "\n",
    "model = icicl.models.ICNP(encoder, decoder, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee381be-5611-48ef-aa09-5e383ab40a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iccnp(model, opt, objective, batch_size, iters, mixture_kernels):\n",
    "    vals = []\n",
    "    iter_iter = tqdm(range(iters))\n",
    "    for iter in iter_iter:\n",
    "        batch_vals = []\n",
    "        for batch in range(batch_size):\n",
    "            # Randomly sample number of context point, number of context datasets, gp kernel.\n",
    "            gp_kernel_idx = np.random.randint(low=0, high=len(mixture_kernels))\n",
    "            kernel_name = list(mixture_kernels.keys())[gp_kernel_idx]\n",
    "            kernel = mixture_kernels[kernel_name]\n",
    "\n",
    "            x_c, y_c, x_t, y_t, d_c = icicl.utils.gp_ic_sampler(\n",
    "                max_n_ic_datasets=10,\n",
    "                max_n_context=30,\n",
    "                kernel=kernel,\n",
    "            )\n",
    "\n",
    "            val = icicl.objectives.iccnp_objective(model, x_c, y_c, x_t, y_t, d_c)\n",
    "            batch_vals.append(val)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        batch_val = sum(batch_vals) / len(batch_vals)\n",
    "        batch_val.backward()\n",
    "        opt.step()\n",
    "        vals.append(batch_val.item())\n",
    "\n",
    "        iter_iter.set_postfix({\"val\": batch_val.item()})\n",
    "\n",
    "    return vals\n",
    "\n",
    "\n",
    "def train_cnp(model, opt, objective, batch_size, iters, mixture_kernels):\n",
    "    vals = []\n",
    "    iter_iter = tqdm(range(iters))\n",
    "    for iter in iter_iter:\n",
    "        batch_vals = []\n",
    "        for batch in range(batch_size):\n",
    "            # Randomly sample number of context point, number of context datasets, gp kernel.\n",
    "            gp_kernel_idx = np.random.randint(low=0, high=len(mixture_kernels))\n",
    "            kernel_name = list(mixture_kernels.keys())[gp_kernel_idx]\n",
    "            kernel = mixture_kernels[kernel_name]\n",
    "\n",
    "            x_c, y_c, x_t, y_t = icicl.utils.gp_sampler(\n",
    "                max_n_context=30, kernel=kernel, dtype=torch.float32\n",
    "            )\n",
    "            val = icicl.objectives.cnp_objective(model, x_c, y_c, x_t, y_t)\n",
    "            batch_vals.append(val)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        batch_val = sum(batch_vals) / len(batch_vals)\n",
    "        batch_val.backward()\n",
    "        opt.step()\n",
    "        vals.append(batch_val.item())\n",
    "\n",
    "        iter_iter.set_postfix({\"val\": batch_val.item()})\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053f2eb-6f7b-44ef-86ff-fc7eff65674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimiser.\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "mixture_kernels = {\n",
    "    \"se\": stheno.EQ().stretch(0.25),\n",
    "    # \"matern\": stheno.Matern52().stretch(0.25),\n",
    "    # \"weakly-periodic\": stheno.EQ().stretch(0.5) * stheno.EQ().periodic(0.5)\n",
    "    \"period\": stheno.EQ().periodic(0.5),\n",
    "}\n",
    "\n",
    "train_vals = train_iccnp(\n",
    "    model,\n",
    "    opt,\n",
    "    iccnp_objective,\n",
    "    batch_size=5,\n",
    "    iters=50_000,\n",
    "    mixture_kernels=mixture_kernels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd3d37-da59-4cec-bc64-fd6d18386b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e123e4-f745-4be0-b37c-607868d6175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iccnp_visualise_1d(model, x_c, y_c, x_t, y_t, d_c, kernel=None, noise=0.05):\n",
    "\n",
    "    x = torch.linspace(-2.0, 2.0, 200).unsqueeze(-1)\n",
    "    with torch.no_grad():\n",
    "        pred_y_t = model(x_c, y_c, x, d_c)\n",
    "        mean, scale = pred_y_t.loc, pred_y_t.scale.pow(2)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot context and target.\n",
    "    plt.scatter(x_c, y_c, label=\"Context\", style=\"train\", s=20)\n",
    "    plt.scatter(x_t, y_t, label=\"Target\", style=\"test\", s=20)\n",
    "\n",
    "    # Plot prediction.\n",
    "    err = 1.96 * scale\n",
    "    plt.plot(x, mean, label=\"Prediction\", style=\"pred\")\n",
    "    plt.fill_between(x, mean - err, mean + err, style=\"pred\")\n",
    "\n",
    "    if kernel is not None:\n",
    "        f = stheno.GP(kernel)\n",
    "        f_post = f | (f(x_c, noise), y_c)\n",
    "        mean, lower, upper = f_post(x).marginal_credible_bounds()\n",
    "\n",
    "        plt.plot(x, mean, label=\"Truth\", style=\"pred2\")\n",
    "        plt.plot(x, lower, style=\"pred2\")\n",
    "        plt.plot(x, upper, style=\"pred2\")\n",
    "\n",
    "    plt.xlim(x.min(), x.max())\n",
    "    wbml.plot.tweak()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa3385-f9fe-452c-b1d6-fd789e87bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_kernel_idx = np.random.randint(low=0, high=len(mixture_kernels))\n",
    "kernel_name = list(mixture_kernels.keys())[gp_kernel_idx]\n",
    "kernel = mixture_kernels[kernel_name]\n",
    "\n",
    "n_context = np.random.randint(low=1, high=30)\n",
    "n_context_datasets = np.random.randint(low=1, high=10)\n",
    "\n",
    "x_c, y_c, x_t, y_t, d_c = gp_ic_sampler(\n",
    "    n_context_datasets=n_context_datasets,\n",
    "    n_context=n_context,\n",
    "    kernel=kernel,\n",
    ")\n",
    "\n",
    "iccnp_visualise_1d(model, x_c, y_c, x_t, y_t, d_c, kernel=kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c78c6-72be-488e-b2b8-6c8227ac2294",
   "metadata": {},
   "source": [
    "# Construct CNP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7cabc7-9764-4dff-9e4b-f20cac9a6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 1\n",
    "y_dim = 1\n",
    "r_dim = 16\n",
    "encoder_num_layers = 3\n",
    "encoder_width = 64\n",
    "decoder_num_layers = 3\n",
    "decoder_width = 64\n",
    "likelihood = icicl.likelihoods.HeteroscedasticNormalLikelihood()\n",
    "\n",
    "cnp_encoder_mlp = icicl.nn.MLP(\n",
    "    in_dim=x_dim + y_dim,\n",
    "    out_dim=r_dim,\n",
    "    num_layers=encoder_num_layers,\n",
    "    width=encoder_width,\n",
    ")\n",
    "cnp_encoder = icicl.deepset.DeepSet(phi=cnp_encoder_mlp)\n",
    "\n",
    "# Can we chain together aggregations, rather than have seperate classes?\n",
    "cnp_decoder_mlp = icicl.nn.MLP(\n",
    "    in_dim=r_dim + x_dim,\n",
    "    out_dim=likelihood.out_dim_multiplier * y_dim,\n",
    "    num_layers=decoder_num_layers,\n",
    "    width=decoder_width,\n",
    ")\n",
    "cnp_decoder = icicl.cnp.CNPDecoder(cnp_decoder_mlp)\n",
    "cnp_model = icicl.models.NP(cnp_encoder, cnp_decoder, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8844524-a3cb-4629-b1f8-6cc88193fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimiser.\n",
    "cnp_opt = torch.optim.Adam(cnp_model.parameters(), lr=1e-3)\n",
    "\n",
    "mixture_kernels = {\n",
    "    \"se\": stheno.EQ().stretch(0.25),\n",
    "    \"matern\": stheno.Matern52().stretch(0.25),\n",
    "    \"weakly-periodic\": stheno.EQ().stretch(0.5) * stheno.EQ().periodic(0.25),\n",
    "}\n",
    "\n",
    "train_vals = train_cnp(\n",
    "    cnp_model,\n",
    "    cnp_opt,\n",
    "    cnp_objective,\n",
    "    batch_size=10,\n",
    "    iters=50_000,\n",
    "    mixture_kernels=mixture_kernels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8e6dd-0014-4e39-ac65-48792ecc180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd9551d-4229-4259-bcfd-564e82b88733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnp_visualise_1d(model, x_c, y_c, x_t, y_t, kernel=None, noise=0.05):\n",
    "\n",
    "    x = torch.linspace(-2.0, 2.0, 200).unsqueeze(-1)\n",
    "    with torch.no_grad():\n",
    "        pred_y_t = model(x_c, y_c, x_t=x)\n",
    "        mean, scale = pred_y_t.loc, pred_y_t.scale.pow(2)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot context and target.\n",
    "    plt.scatter(x_c, y_c, label=\"Context\", style=\"train\", s=20)\n",
    "    plt.scatter(x_t, y_t, label=\"Target\", style=\"test\", s=20)\n",
    "\n",
    "    # Plot prediction.\n",
    "    err = 1.96 * scale\n",
    "    plt.plot(x, mean, label=\"Prediction\", style=\"pred\")\n",
    "    plt.fill_between(x, mean - err, mean + err, style=\"pred\")\n",
    "\n",
    "    if kernel is not None:\n",
    "        f = stheno.GP(kernel)\n",
    "        f_post = f | (f(x_c, noise), y_c)\n",
    "        mean, lower, upper = f_post(x).marginal_credible_bounds()\n",
    "\n",
    "        plt.plot(x, mean, label=\"Truth\", style=\"pred2\")\n",
    "        plt.plot(x, lower, style=\"pred2\")\n",
    "        plt.plot(x, upper, style=\"pred2\")\n",
    "\n",
    "    plt.xlim(x.min(), x.max())\n",
    "    wbml.plot.tweak()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba5aae-93c9-4397-9024-8a542da970c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample number of context point, number of context datasets, gp kernel.\n",
    "gp_kernel_idx = np.random.randint(low=0, high=len(mixture_kernels))\n",
    "kernel_name = list(mixture_kernels.keys())[gp_kernel_idx]\n",
    "kernel = mixture_kernels[kernel_name]\n",
    "\n",
    "n_context = np.random.randint(low=1, high=30)\n",
    "\n",
    "x_c, y_c, x_t, y_t = gp_sampler(\n",
    "    n_context=n_context,\n",
    "    kernel=kernel,\n",
    ")\n",
    "\n",
    "cnp_visualise_1d(cnp_model, x_c, y_c, x_t, y_t, kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb6e0f-0ada-47d7-a3a2-9d6d06998d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
