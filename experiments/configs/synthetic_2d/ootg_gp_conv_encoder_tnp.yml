# This is 2d!'

generators:
  train:
    _target_: tnp.data.on_off_grid.SyntheticOOTGGenerator
    off_grid_generator: ${generators.off_grid_generator_train}
    grid_range: ${params.data_range}
    points_per_unit: ${params.points_per_unit}
    used_modality: ${params.used_modality}
    samples_per_epoch: 16000
    batch_size: 16
    deterministic: ${params.deterministic}
  val:
    _target_: tnp.data.on_off_grid.SyntheticOOTGGenerator
    off_grid_generator: ${generators.off_grid_generator_val}
    grid_range: ${params.data_range}
    points_per_unit: ${params.points_per_unit}
    used_modality: ${params.used_modality}
    samples_per_epoch: 4000
    batch_size: 16
    deterministic: ${params.deterministic}
    
  off_grid_generator_train:
    _target_: tnp.data.gp.RandomScaleGPGenerator
    dim: ${params.dim}
    kernel_type: eq
    min_log10_lengthscale: -0.602
    max_log10_lengthscale: 0.602
    noise_std: 0.2
    num_tasks: ${params.gp_num_tasks}
    task_correlation: ${params.task_correlation}
    min_num_ctx: 1
    max_num_ctx: 64
    min_num_trg: 128
    max_num_trg: 128
    context_range: [[-2.0, 2.0], [-2.0, 2.0]]
    target_range: ${params.data_range}
    samples_per_epoch: ${generators.train.samples_per_epoch}
    batch_size: ${generators.train.batch_size}
  off_grid_generator_val:
    _target_: tnp.data.gp.RandomScaleGPGenerator
    dim: ${params.dim}
    kernel_type: eq
    min_log10_lengthscale: -0.602
    max_log10_lengthscale: 0.602
    noise_std: 0.2
    num_tasks: ${params.gp_num_tasks}
    task_correlation: ${params.task_correlation}
    min_num_ctx: 1
    max_num_ctx: 64
    min_num_trg: 128
    max_num_trg: 128
    context_range: [[-2.0, 2.0], [-2.0, 2.0]]
    target_range: ${params.data_range}
    samples_per_epoch: ${generators.val.samples_per_epoch}
    batch_size: ${generators.val.batch_size}

model:
  _target_: tnp.models.ootg_tnp.OOTG_TNPD
  encoder: ${tnpd_encoder}
  decoder: ${tnpd_decoder}
  likelihood: ${likelihood}

tnpd_encoder:
  _target_: tnp.models.ootg_tnp.OOTG_TNPDEncoder
  grid_encoder: ${grid_encoder}
  transformer_encoder: ${transformer_encoder}
  xy_encoder: ${xy_encoder}

grid_encoder:
  _target_: tnp.networks.grid_encoders.SetConvGridEncoder
  ard_num_dims: ${params.dim}
  init_lengthscale: ${eval:'2 * 1 / ${params.points_per_unit}'}

transformer_encoder:
  _target_: tnp.networks.grid_transformer.GridTransformerEncoder
  mhca_layer: ${mhca_layer}
  mhsa_layer: ${mhsa_layer}
  num_layers: ${params.num_layers}

mhca_layer:
  _target_: tnp.networks.attention_layers.MultiHeadCrossAttentionLayer
  embed_dim: ${params.embed_dim}
  num_heads: ${params.num_heads}
  head_dim: ${params.head_dim}
  feedforward_dim: ${params.embed_dim}
  norm_first: ${params.norm_first}

mhsa_layer:
  _target_: tnp.networks.attention_layers.MultiHeadSelfAttentionLayer
  embed_dim: ${params.embed_dim}
  num_heads: ${params.num_heads}
  head_dim: ${params.head_dim}
  feedforward_dim: ${params.embed_dim}
  norm_first: ${params.norm_first}

xy_encoder:
  _target_: tnp.networks.mlp.MLP
  in_dim: ${eval:'3 + ${params.dim}'} # 2 flag dimensions (preprocessing) and ydim=1
  out_dim: ${params.embed_dim}
  num_layers: 2
  width: ${params.embed_dim}

tnpd_decoder:
  _target_: tnp.models.tnp.TNPDDecoder
  z_decoder: ${z_decoder}

z_decoder:
  _target_: tnp.networks.mlp.MLP
  in_dim: ${params.embed_dim}
  out_dim: 2 # 1 for std and 1 for means
  num_layers: 2
  width: ${params.embed_dim}

likelihood:
  _target_: tnp.likelihoods.gaussian.HeteroscedasticNormalLikelihood

optimiser:
  _target_: torch.optim.AdamW
  _partial_: True
  lr: 5.0e-4

params:
  epochs: 200
  deterministic: False # makes it generate whole dataset up front and re-use over epochs
  used_modality: BOTH

  dim: 2
  data_range: [[-4.0, 4.0], [-4.0, 4.0]]
  gp_num_tasks: 2
  task_correlation: 0.8
  points_per_unit: 1 # 1 here gives 64 datapoints already.

  embed_dim: 128
  num_heads: 8
  head_dim: 16
  norm_first: True
  num_layers: 5



misc:
  project: tnp-2d-data
  name: conv_set_encoder_tnp-data=${params.used_modality}-taskCor=${params.task_correlation}-ppu=${params.points_per_unit}
  gradient_clip_val: 0.5
  plot_interval: 10
  resume_from_checkpoint: null