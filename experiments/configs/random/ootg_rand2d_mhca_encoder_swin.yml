# File inspired from 'efficient-tnpd-synthetic-1d.yml'

# OUTDATED -> UPDATE BEFORE USE

generators:
  train:
    _target_: icicl.data.on_off_grid.RandomOOTGGenerator
    num_off_grid_context: ${params.num_off_the_grid}
    num_on_grid_per_dim: ${params.on_grid_per_dim}
    num_targets: ${params.num_off_the_grid}
    dim: ${params.dim}
    samples_per_epoch: 16000
    batch_size: 16
    deterministic: ${params.deterministic}
  val:
    _target_: icicl.data.on_off_grid.RandomOOTGGenerator
    num_off_grid_context: ${params.num_off_the_grid}
    num_on_grid_per_dim: ${params.on_grid_per_dim}
    num_targets: ${params.num_off_the_grid}
    dim: ${params.dim}
    samples_per_epoch: 4000
    batch_size: 16
    deterministic: ${params.deterministic}
    
model:
  _target_: icicl.models.ootg_tnp.OOTG_TNPD
  encoder: ${tnpd_encoder}
  decoder: ${tnpd_decoder}
  likelihood: ${likelihood}

tnpd_encoder:
  _target_: icicl.models.ootg_swin.OOTG_SwinEncoder
  grid_encoder: ${grid_encoder}
  transformer_encoder: ${transformer_encoder}
  xy_encoder: ${xy_encoder}

grid_encoder: 
  _target_: icicl.networks.grid_encoders.PseudoTokenGridEncoder
  embed_dim: ${params.embed_dim}
  num_latents: 10000
  mhca_layer: ${grid_mhca_layer}

grid_mhca_layer:
  _target_: icicl.networks.attention_layers.MultiHeadCrossAttentionLayer
  embed_dim: ${params.embed_dim}
  num_heads: ${params.num_heads}
  head_dim: ${params.head_dim}
  feedforward_dim: ${params.embed_dim}
  norm_first: ${params.norm_first}

transformer_encoder:
  _target_: icicl.models.ootg_swin.SWINTransformerEncoder
  mhca_layer: ${mhca_layer}
  swin_layer: ${swin_layer}
  num_layers: ${params.num_layers}

swin_layer:
  _target_: icicl.networks.swin_attention.SWINAttentionLayer
  window_sizes: ${params.window_sizes}
  embed_dim: ${params.embed_dim}
  num_heads: ${params.num_heads}
  head_dim: ${params.head_dim}
  feedforward_dim: ${params.embed_dim}
  norm_first: ${params.norm_first}

mhca_layer:
  _target_: icicl.networks.attention_layers.MultiHeadCrossAttentionLayer
  embed_dim: ${params.embed_dim}
  num_heads: ${params.num_heads}
  head_dim: ${params.head_dim}
  feedforward_dim: ${params.embed_dim}
  norm_first: ${params.norm_first}

xy_encoder:
  _target_: icicl.networks.mlp.MLP
  in_dim: ${eval:'3 + ${params.dim}'} # 2 flag dimensions (preprocessing) and ydim=1
  out_dim: ${params.embed_dim}
  num_layers: 2
  width: ${params.embed_dim}

tnpd_decoder:
  _target_: icicl.models.tnp.TNPDDecoder
  z_decoder: ${z_decoder}

z_decoder:
  _target_: icicl.networks.mlp.MLP
  in_dim: ${params.embed_dim}
  out_dim: 2 # 1 for std and 1 for means
  num_layers: 2
  width: ${params.embed_dim}

likelihood:
  _target_: icicl.likelihoods.gaussian.HeteroscedasticNormalLikelihood

optimiser:
  _target_: torch.optim.AdamW
  _partial_: True
  lr: 5.0e-4

params:
  epochs: 200
  deterministic: False # makes it generate whole dataset up front and re-use over epochs
  ignore_on_grid: False

  dim: 2
  on_grid_per_dim: 100 # (so 10k)
  num_off_the_grid: 32

  embed_dim: 128
  num_heads: 8
  head_dim: 16
  norm_first: True
  num_layers: 5

  window_sizes: [20, 20] # check that on_grid_per_dim properly divisible by this!


misc:
  logging: False
  resume_from_checkpoint: null