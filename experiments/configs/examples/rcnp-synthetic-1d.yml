generators:
  train:
    _target_: icicl.data.gp.RandomScaleGPGenerator
    dim: ${params.dim}
    kernel_type: eq
    min_log10_lengthscale: -0.602
    max_log10_lengthscale: 0.602
    noise_std: 0.2
    min_num_ctx: 1
    max_num_ctx: 64
    min_num_trg: 128
    max_num_trg: 128
    context_range: [[-2.0, 2.0]]
    target_range: [[-3.0, 3.0]]
    samples_per_epoch: 16384
    batch_size: 16
  val:
    _target_: icicl.data.gp.RandomScaleGPGenerator
    dim: ${params.dim}
    kernel_type: eq
    min_log10_lengthscale: -0.602
    max_log10_lengthscale: 0.602
    noise_std: 0.2
    min_num_ctx: 1
    max_num_ctx: 64
    min_num_trg: 128
    max_num_trg: 128
    context_range: [[-2.0, 2.0]]
    target_range: [[-3.0, 3.0]]
    samples_per_epoch: 4096
    batch_size: 16

model:
  _target_: icicl.models.rcnp.RCNP
  encoder: ${rcnp_encoder}
  decoder: ${cnp_decoder}
  likelihood: ${likelihood}

rcnp_encoder:
  _target_: icicl.models.rcnp.RCNPEncoder
  relational_encoder: ${relational_encoder}
  diagonal_encoding: True

relational_encoder:
  _target_: icicl.networks.mlp.MLP
  in_dim: ${eval:'${params.dim} + ${params.dim} + 1'}
  out_dim: ${params.embed_dim}
  num_layers: ${params.num_layers}
  width: ${params.embed_dim}

cnp_decoder:
  _target_: icicl.models.cnp.CNPDecoder
  z_decoder: ${z_decoder}

z_decoder:
  _target_: icicl.networks.mlp.MLP
  in_dim: ${eval:'${params.dim} + ${params.embed_dim}'}
  out_dim: 2
  num_layers: ${params.num_layers}
  width: ${params.embed_dim}

likelihood:
  _target_: icicl.likelihoods.gaussian.HeteroscedasticNormalLikelihood

optimiser:
  _target_: torch.optim.Adam
  _partial_: True
  lr: 5e-4

params:
  epochs: 200
  dim: 1
  embed_dim: 32
  num_layers: 5

misc:
  project: rcnp
  name: synthetic-1d-L${params.num_layers}-D${params.embed_dim}
  resume_from_checkpoint: null
  plot_ar_mode: False
  logging: True
